---
description: Jira-driven test generation workflow with Confluence integration
---

# Jira Test Generation Workflow

When the `generate-tests-from-jira` command is invoked with a Jira issue ID, follow this systematic workflow:

## Step 1: Fetch Jira Context
- Use `mcp_Atlassian_getJiraIssue` with the cloudId and issue ID
- Extract: summary, description, acceptance criteria, issue type, status
- Note the files or components mentioned in the description

## Step 2: Find Confluence Documentation
- Use `mcp_Atlassian_getJiraIssueRemoteIssueLinks` to find linked Confluence pages
- If remote links exists, fetch each Confluence page using `mcp_Atlassian_getConfluencePage`
- If no links found, use `mcp_Atlassian_searchConfluenceUsingCql` with keywords from the Jira summary

## Step 3: Analyze Documentation for Edge Cases
From Confluence pages, identify:
- Technical specifications and constraints
- Known edge cases or error scenarios
- Input validation requirements
- Boundary conditions
- Integration points with other systems
- Performance requirements

## Step 4: Identify Files to Test
- Parse Jira description to identify files that were modified or need testing
- Read the identified source files to understand the implementation
- Identify all public functions, classes, and methods that need test coverage

## Step 5: Clarify Ambiguities
If edge cases or requirements are unclear:
- Ask specific questions about:
  - Input validation boundaries
  - Error handling expectations
  - Integration behavior
  - Performance requirements
- Keep questions focused and actionable

## Step 6: Generate Test Plan
Create a comprehensive test plan showing:

### Files to Test
List each file with line references to functions/methods

### Test Scenarios
Organize by:
1. **Happy Path Tests** - Normal expected behavior
2. **Edge Cases from Confluence** - Documented special cases
3. **Error Handling** - Invalid inputs, exceptions, failures
4. **Boundary Conditions** - Min/max values, empty/null cases
5. **Integration Tests** - If multiple components interact

### Test Structure
- Use Jest framework with TypeScript
- Follow pattern: `describe` blocks for each function/class
- Test naming: `[specific behavior] should [expect]`
- Include mocking strategy where needed
- Self-documenting code (no comments unless public API)

## Step 7: Wait for Approval
- Present the test plan clearly
- Wait for user confirmation before proceeding
- Allow user to request modifications to the plan

## Step 8: Generate Tests
After approval:
- Create or update test files following the pattern in existing tests
- Place tests adjacent to source files (e.g., `index.ts` â†’ `index.test.ts`)
- Use proper TypeScript types
- Follow existing test conventions (test naming, structure)
- Ensure tests are runnable with `npm test`
- Verify no linter errors introduced

## Test Quality Standards
- Each test should be atomic and independent
- Use descriptive test names that explain the behavior
- Mock external dependencies appropriately
- Cover all code paths identified in the Jira task
- Tests should be maintainable and readable without comments
